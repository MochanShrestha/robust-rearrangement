{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "from src.common.files import get_raw_paths, get_processed_path\n",
    "from src.visualization.render_mp4 import unpickle_data, pickle_data\n",
    "from src.visualization.render_mp4 import create_mp4_jupyter\n",
    "\n",
    "from furniture_bench.robot.robot_state import filter_and_concat_robot_state\n",
    "\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_replace_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for folder in tqdm(list(dirs)):\n",
    "            folder_path = os.path.join(root, folder)\n",
    "            extracted_files = os.listdir(folder_path)\n",
    "\n",
    "            if len(extracted_files) > 0:\n",
    "                file_to_extract = extracted_files[0]\n",
    "                file_path = os.path.join(folder_path, file_to_extract)\n",
    "\n",
    "                new_file_name = f\"{folder}.{file_to_extract.split('.')[-1]}\"\n",
    "                new_file_path = os.path.join(root, new_file_name)\n",
    "\n",
    "                shutil.move(file_path, new_file_path)\n",
    "                shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where the folders are located\n",
    "directory = \"/data/scratch-oc40/pulkitag/ankile/furniture-data/raw/real/place_shade/teleop/low/success\"\n",
    "\n",
    "# Call the function to extract and replace files\n",
    "extract_and_replace_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_paths = get_raw_paths(\n",
    "    environment=\"real\",\n",
    "    demo_outcome=\"success\",\n",
    "    demo_source=\"teleop\",\n",
    "    randomness=\"low\",\n",
    "    task=\"place_shade\",\n",
    ")\n",
    "\n",
    "len(raw_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data to be stored with delta actions in the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_path in tqdm(raw_paths):\n",
    "    data = unpickle_data(raw_path)\n",
    "    robot_state = data[\"robot_state\"]\n",
    "\n",
    "    for i in range(len(robot_state)):\n",
    "        robot_state[i] = {\n",
    "            \"ee_pos\": robot_state[i][\"ee_pose\"][:3],\n",
    "            \"ee_quat\": robot_state[i][\"ee_pose\"][3:],\n",
    "            \"gripper_width\": np.array([robot_state[i][\"gripper_width\"]]),\n",
    "        }\n",
    "\n",
    "    # Pack the robot state, color_image1, color_image2 into a single observation dict in a list\n",
    "    data[\"observations\"] = [\n",
    "        {\n",
    "            \"robot_state\": robot_state[i],\n",
    "            \"color_image1\": data[\"image_wrist\"][i][\"rgb\"],\n",
    "            \"color_image2\": data[\"image_front\"][i][\"rgb\"],\n",
    "        }\n",
    "        for i in range(len(robot_state))\n",
    "    ]\n",
    "\n",
    "    del data[\"image_wrist\"]\n",
    "    del data[\"image_front\"]\n",
    "    del data[\"robot_state\"]\n",
    "\n",
    "    actions = np.array(data[\"actions\"])\n",
    "    robot_state = np.array(\n",
    "        [filter_and_concat_robot_state(o[\"robot_state\"]) for o in data[\"observations\"]],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    robot_pos, robot_quat, gripper_width = (\n",
    "        robot_state[:, :3],\n",
    "        robot_state[:, 3:7],\n",
    "        robot_state[:, -1:],\n",
    "    )\n",
    "    action_pos, action_quat, action_gripper = (\n",
    "        actions[:, :3],\n",
    "        actions[:, 3:7],\n",
    "        actions[:, -1:],\n",
    "    )\n",
    "\n",
    "    # Calclate what the delta action is\n",
    "    action_delta_pos = action_pos - robot_pos\n",
    "\n",
    "    # Calculate the delta quaternion\n",
    "    robot_r = R.from_quat(robot_quat)\n",
    "    action_r = R.from_quat(action_quat)\n",
    "    action_delta_r = robot_r.inv() * action_r\n",
    "    action_delta_quat = action_delta_r.as_quat()\n",
    "\n",
    "    # Concatenate the delta action\n",
    "    action_delta = np.concatenate(\n",
    "        [action_delta_pos, action_delta_quat, action_gripper], axis=-1\n",
    "    )\n",
    "\n",
    "    data[\"actions\"] = action_delta\n",
    "    data[\"furniture\"] = \"place_shade\"\n",
    "    data[\"success\"] = True\n",
    "    pickle_data(data, raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data[\"robot_state\"][0][\"gripper_width\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = get_processed_path(\n",
    "    environment=\"real\",\n",
    "    demo_outcome=\"success\",\n",
    "    demo_source=\"teleop\",\n",
    "    randomness=\"low\",\n",
    "    task=\"place_shade\",\n",
    ")\n",
    "\n",
    "zarr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zarr.open(zarr_path)\n",
    "\n",
    "list(z.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print ranges of the robot_state and actions\n",
    "robot_state = z[\"robot_state\"][:]\n",
    "actions = z[\"action/pos\"][:]\n",
    "\n",
    "robot_state.shape, actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(robot_state.min(axis=0).round(3))\n",
    "print(robot_state.max(axis=0).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actions.min(axis=0).round(3))\n",
    "print(actions.max(axis=0).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "new_raw_paths = list(\n",
    "    Path(\n",
    "        \"/data/pulkitag/data/anthony/to_share/real_world_furniture_assembly_demos/lamp_shade_pick_place_basic_rs2/\"\n",
    "    ).rglob(\"**/*.pkl\")\n",
    ")\n",
    "\n",
    "len(new_raw_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = unpickle_data(new_raw_paths[2])\n",
    "\n",
    "raw_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid1 = np.stack([img[\"rgb\"] for img in raw_data[\"image_front\"]])\n",
    "vid2 = np.stack([img[\"rgb\"] for img in raw_data[\"image_wrist\"]])\n",
    "\n",
    "video = np.concatenate([vid1, vid2], axis=2)\n",
    "\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mp4_jupyter(video, \"real_3.mp4\", fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(raw_data[\"actions\"]).max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teleop_demo = unpickle_data(\n",
    "    \"/data/scratch-oc40/pulkitag/ankile/furniture-data/raw/sim/one_leg/teleop/low/diffik/success/2024-04-27T17:33:14.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teleop_demo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teleop_demo[\"observations\"][0][\"robot_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at videos from the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "from src.common.files import get_processed_path\n",
    "from src.visualization.render_mp4 import create_mp4_jupyter, annotate_frames_with_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = get_processed_path(\n",
    "    controller=\"diffik\",\n",
    "    domain=\"real\",\n",
    "    demo_outcome=\"success\",\n",
    "    demo_source=\"teleop\",\n",
    "    randomness=\"low\",\n",
    "    task=\"place_shade\",\n",
    ")\n",
    "\n",
    "print(zarr_path)\n",
    "\n",
    "z = zarr.open(zarr_path)\n",
    "\n",
    "list(z.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_ends = z[\"episode_ends\"][:]\n",
    "print(ep_ends)\n",
    "\n",
    "images = z[\"color_image2\"][:]\n",
    "\n",
    "# Split the color images into episodes\n",
    "ep_images = np.split(images, ep_ends[:-1])\n",
    "\n",
    "len(ep_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the delta position action for each episode\n",
    "action_pos = z[\"action/pos\"][:, :3]\n",
    "action_pos = np.split(action_pos, ep_ends[:-1])\n",
    "\n",
    "robot_pos = z[\"robot_state\"][:, :3]\n",
    "robot_pos = np.split(robot_pos, ep_ends[:-1])\n",
    "\n",
    "action_delta_pos = [action - robot for action, robot in zip(action_pos, robot_pos)]\n",
    "\n",
    "len(action_delta_pos), action_delta_pos[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def add_black_space_and_text(\n",
    "    frames, delta_action, text_color=(255, 255, 255), font_scale=0.5, thickness=1\n",
    "):\n",
    "    # Get the dimensions of the frames\n",
    "    T, H, W, C = frames.shape\n",
    "\n",
    "    # Define the height of the black space\n",
    "    black_space_height = 50\n",
    "\n",
    "    # Create a black space array\n",
    "    black_space = np.zeros((T, black_space_height, W, C), dtype=np.uint8)\n",
    "\n",
    "    # Concatenate the frames with the black space\n",
    "    frames_with_space = np.concatenate((frames, black_space), axis=1)\n",
    "\n",
    "    # Add text to the black space for each frame\n",
    "    for i in range(T):\n",
    "        text = f\"{delta_action[i].round(3)}\"\n",
    "        cv2.putText(\n",
    "            frames_with_space[i],\n",
    "            text,\n",
    "            (10, H + black_space_height - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            font_scale,\n",
    "            text_color,\n",
    "            thickness,\n",
    "        )\n",
    "\n",
    "    return frames_with_space\n",
    "\n",
    "\n",
    "# Make a video of the episodes\n",
    "for i, (ep, delta_action) in enumerate(zip(ep_images, action_delta_pos)):\n",
    "    ep = annotate_frames_with_speed(frames=ep, fps=5)\n",
    "    ep_with_text = add_black_space_and_text(ep, delta_action)\n",
    "    create_mp4_jupyter(ep_with_text, f\"ep_{i}.mp4\", fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
