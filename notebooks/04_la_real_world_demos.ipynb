{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "from src.common.files import get_raw_paths, get_processed_path\n",
    "from src.visualization.render_mp4 import unpickle_data, pickle_data\n",
    "from src.visualization.render_mp4 import create_mp4_jupyter\n",
    "\n",
    "from furniture_bench.robot.robot_state import filter_and_concat_robot_state\n",
    "\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_replace_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for folder in tqdm(list(dirs)):\n",
    "            folder_path = os.path.join(root, folder)\n",
    "            extracted_files = os.listdir(folder_path)\n",
    "            \n",
    "            if len(extracted_files) > 0:\n",
    "                file_to_extract = extracted_files[0]\n",
    "                file_path = os.path.join(folder_path, file_to_extract)\n",
    "                \n",
    "                new_file_name = f\"{folder}.{file_to_extract.split('.')[-1]}\"\n",
    "                new_file_path = os.path.join(root, new_file_name)\n",
    "                \n",
    "                shutil.move(file_path, new_file_path)\n",
    "                shutil.rmtree(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where the folders are located\n",
    "directory = \"/data/scratch-oc40/pulkitag/ankile/furniture-data/raw/real/place_shade/teleop/low/success\"\n",
    "\n",
    "# Call the function to extract and replace files\n",
    "extract_and_replace_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_paths = get_raw_paths(\n",
    "    environment=\"real\",\n",
    "    demo_outcome=\"success\",\n",
    "    demo_source=\"teleop\",\n",
    "    randomness=\"low\",\n",
    "    task=\"place_shade\",\n",
    ")\n",
    "\n",
    "len(raw_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data to be stored with delta actions in the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_path in tqdm(raw_paths):\n",
    "    data = unpickle_data(raw_path)\n",
    "    robot_state = data[\"robot_state\"]\n",
    "    \n",
    "    for i in range(len(robot_state)):\n",
    "        robot_state[i] = {\n",
    "            \"ee_pos\": robot_state[i][\"ee_pose\"][:3],\n",
    "            \"ee_quat\": robot_state[i][\"ee_pose\"][3:],\n",
    "            \"gripper_width\": np.array([robot_state[i][\"gripper_width\"]]),\n",
    "        }\n",
    "\n",
    "    # Pack the robot state, color_image1, color_image2 into a single observation dict in a list\n",
    "    data[\"observations\"] = [\n",
    "        {\n",
    "            \"robot_state\": robot_state[i],\n",
    "            \"color_image1\": data[\"image_wrist\"][i][\"rgb\"],\n",
    "            \"color_image2\": data[\"image_front\"][i][\"rgb\"],\n",
    "        }\n",
    "        for i in range(len(robot_state))\n",
    "    ]\n",
    "\n",
    "    del data[\"image_wrist\"]\n",
    "    del data[\"image_front\"]\n",
    "    del data[\"robot_state\"]\n",
    "    \n",
    "    actions = np.array(data[\"actions\"])\n",
    "    robot_state = np.array(\n",
    "            [filter_and_concat_robot_state(o[\"robot_state\"]) for o in data[\"observations\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "    robot_pos, robot_quat, gripper_width = robot_state[:, :3], robot_state[:, 3:7], robot_state[:, -1:]\n",
    "    action_pos, action_quat, action_gripper = actions[:, :3], actions[:, 3:7], actions[:, -1:]\n",
    "\n",
    "    # Calclate what the delta action is\n",
    "    action_delta_pos = action_pos - robot_pos\n",
    "\n",
    "    # Calculate the delta quaternion\n",
    "    robot_r = R.from_quat(robot_quat)\n",
    "    action_r = R.from_quat(action_quat)\n",
    "    action_delta_r = robot_r.inv() * action_r\n",
    "    action_delta_quat = action_delta_r.as_quat()\n",
    "\n",
    "    # Concatenate the delta action\n",
    "    action_delta = np.concatenate([action_delta_pos, action_delta_quat, action_gripper], axis=-1)\n",
    "\n",
    "    data[\"actions\"] = action_delta\n",
    "    data[\"furniture\"] = \"place_shade\"\n",
    "    data[\"success\"] = True\n",
    "    pickle_data(data, raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data[\"robot_state\"][0][\"gripper_width\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = get_processed_path(\n",
    "    environment=\"real\",\n",
    "    demo_outcome=\"success\",\n",
    "    demo_source=\"teleop\",\n",
    "    randomness=\"low\",\n",
    "    task=\"place_shade\",\n",
    ")\n",
    "\n",
    "zarr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zarr.open(zarr_path)\n",
    "\n",
    "list(z.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print ranges of the robot_state and actions\n",
    "robot_state = z[\"robot_state\"][:]\n",
    "actions = z[\"action/pos\"][:]\n",
    "\n",
    "robot_state.shape, actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(robot_state.min(axis=0).round(3))\n",
    "print(robot_state.max(axis=0).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actions.min(axis=0).round(3))\n",
    "print(actions.max(axis=0).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "new_raw_paths = list(Path(\"/data/pulkitag/data/anthony/to_share/real_world_furniture_assembly_demos/lamp_shade_pick_place_basic_rs2/\").rglob(\"**/*.pkl\"))\n",
    "\n",
    "len(new_raw_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = unpickle_data(new_raw_paths[2])\n",
    "\n",
    "raw_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid1 = np.stack([img[\"rgb\"] for img in raw_data[\"image_front\"]])\n",
    "vid2 = np.stack([img[\"rgb\"] for img in raw_data[\"image_wrist\"]])\n",
    "\n",
    "video = np.concatenate([vid1, vid2], axis=2)\n",
    "\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mp4_jupyter(video, \"real_3.mp4\", fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.array(raw_data[\"actions\"]).max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teleop_demo = unpickle_data(\"/data/scratch-oc40/pulkitag/ankile/furniture-data/raw/sim/one_leg/teleop/low/diffik/success/2024-04-27T17:33:14.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teleop_demo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teleop_demo['observations'][0][\"robot_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at videos from the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "from src.common.files import get_processed_path\n",
    "from src.visualization.render_mp4 import create_mp4_jupyter, annotate_frames_with_speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = get_processed_path(\n",
    "    environment=\"real\",\n",
    "    demo_outcome=\"success\",\n",
    "    demo_source=\"teleop\",\n",
    "    randomness=\"low\",\n",
    "    task=\"place_shade\",\n",
    ")\n",
    "\n",
    "print(zarr_path)\n",
    "\n",
    "z = zarr.open(zarr_path)\n",
    "\n",
    "list(z.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_ends = z[\"episode_ends\"][:]\n",
    "print(ep_ends)\n",
    "\n",
    "images = z[\"color_image2\"][:]\n",
    "\n",
    "# Split the color images into episodes\n",
    "ep_images = np.split(images, ep_ends[:-1])\n",
    "\n",
    "len(ep_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a video of the episodes\n",
    "for i, ep in enumerate(ep_images):\n",
    "    ep = annotate_frames_with_speed(frames=ep, fps=20)\n",
    "    create_mp4_jupyter(ep, f\"ep_{i}.mp4\", fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
